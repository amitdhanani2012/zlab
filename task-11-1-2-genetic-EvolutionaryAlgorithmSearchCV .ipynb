{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/astrophysics-sklearn-deap/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# USE sklearn 1.0.2 and sklearn-deap 0.3.0 (git clone and python setup.py install) For task EvolutionaryAlgorithmSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.load_digits()\n",
    "X = d.data\n",
    "y = d.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/astrophysics-sklearn-deap/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/test/anaconda3/envs/astrophysics-sklearn-deap/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 1, 1, 1, 1, 1] and maxint [89, 62, 44, 8, 9, 1] detected\n",
      "--- Evolve in 45927000 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t10    \t0.894602\t0.873122\t0.926544\t0.0158167\n",
      "1  \t7     \t0.913244\t0.893712\t0.926544\t0.0126884\n",
      "2  \t3     \t0.921425\t0.896494\t0.92877 \t0.00958638\n",
      "3  \t8     \t0.926878\t0.926544\t0.92877 \t0.000712646\n",
      "4  \t6     \t0.926711\t0.913189\t0.931553\t0.00470911 \n",
      "5  \t6     \t0.928325\t0.926544\t0.92877 \t0.000738258\n",
      "Best individual is: {'n_estimators': 70, 'max_features': 3, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "with fitness: 0.9315525876460768\n",
      "{'n_estimators': 70, 'max_features': 3, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Accuracy:0.9315525876460768\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': np.logspace(1,1.8,num = 10 ,base=20,dtype='int'),\n",
    "    'max_depth': np.logspace(1,2,num = 10 ,base=10,dtype='int'),\n",
    "    \"max_features\":np.logspace(0.2,1,num = 5 ,base=8,dtype='int'),\n",
    "    \"min_samples_split\":np.logspace(0.4, 1, num=5, base=10, dtype='int'), #[2, 3, 5, 7, 10],\n",
    "    \"min_samples_leaf\":np.logspace(0.1,1,num = 5 ,base=11,dtype='int'),\n",
    "    \"criterion\":['gini','entropy']\n",
    "}\n",
    "rf_params = {\n",
    "    'n_estimators': range(10,100),\n",
    "    \"max_features\":range(1,64),\n",
    "    'max_depth': range(5,50),\n",
    "    \"min_samples_split\":range(2,11),\n",
    "    \"min_samples_leaf\":range(1,11),\n",
    "    #Categorical(name='criterion', categories=['gini','entropy'])#\n",
    "    \"criterion\":['gini','entropy']\n",
    "}\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "# Set the hyperparameters of GA \n",
    "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
    "                                   params=rf_params,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   cv=3,\n",
    "                                   verbose=1,\n",
    "                                   population_size=10,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=1)\n",
    "ga1.fit(X, y)\n",
    "print(ga1.best_params_)\n",
    "print(\"Accuracy:\"+ str(ga1.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/astrophysics-sklearn-deap/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/test/anaconda3/envs/astrophysics-sklearn-deap/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [2, 1] and maxint [999, 3] detected\n",
      "--- Evolve in 4000 possible combinations ---\n",
      "gen\tnevals\tavg    \tmin     \tmax     \tstd      \n",
      "0  \t10    \t0.94246\t0.763495\t0.973845\t0.0610608\n",
      "1  \t8     \t0.97084\t0.943795\t0.973845\t0.00901503\n",
      "2  \t4     \t0.972677\t0.962159\t0.973845\t0.00350584\n",
      "3  \t7     \t0.973845\t0.973845\t0.973845\t0         \n",
      "4  \t1     \t0.973901\t0.973845\t0.974402\t0.000166945\n",
      "5  \t6     \t0.974068\t0.973845\t0.974402\t0.00027262 \n",
      "Best individual is: {'C': 6.730646889908404, 'kernel': 'rbf'}\n",
      "with fitness: 0.9744017807456873\n",
      "{'C': 6.730646889908404, 'kernel': 'rbf'}\n",
      "Accuracy:0.9744017807456873\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "rf_params = {\n",
    "    'C': np.random.uniform(0,50,1000),\n",
    "    \"kernel\":['linear','poly','rbf','sigmoid']\n",
    "}\n",
    "clf = SVC(gamma='scale')\n",
    "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
    "                                   params=rf_params,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   cv=3,\n",
    "                                   verbose=1,\n",
    "                                   population_size=10,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=1)\n",
    "ga1.fit(X, y)\n",
    "print(ga1.best_params_)\n",
    "print(\"Accuracy:\"+ str(ga1.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/astrophysics-sklearn-deap/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/test/anaconda3/envs/astrophysics-sklearn-deap/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1] and maxint [18] detected\n",
      "--- Evolve in 19 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd       \n",
      "0  \t10    \t0.954869\t0.945465\t0.963829\t0.00638599\n",
      "1  \t3     \t0.959265\t0.947691\t0.963829\t0.00502563\n",
      "2  \t8     \t0.961603\t0.956594\t0.963829\t0.00252572\n",
      "3  \t5     \t0.962827\t0.962716\t0.963829\t0.00033389\n",
      "4  \t6     \t0.962938\t0.962716\t0.963829\t0.000445186\n",
      "5  \t8     \t0.961658\t0.954368\t0.963829\t0.00305255 \n",
      "Best individual is: {'n_neighbors': 4}\n",
      "with fitness: 0.9638286032276016\n",
      "{'n_neighbors': 4}\n",
      "Accuracy:0.9638286032276016\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "rf_params = {\n",
    "    'n_neighbors': range(1,20),\n",
    "}\n",
    "clf = KNeighborsClassifier()\n",
    "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
    "                                   params=rf_params,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   cv=3,\n",
    "                                   verbose=1,\n",
    "                                   population_size=10,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=1)\n",
    "ga1.fit(X, y)\n",
    "print(ga1.best_params_)\n",
    "print(\"Accuracy:\"+ str(ga1.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/astrophysics-sklearn-deap/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/test/anaconda3/envs/astrophysics-sklearn-deap/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 1, 1, 1, 1, 1] and maxint [2, 1, 2, 89, 1, 16] detected\n",
      "--- Evolve in 55080 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax\tstd      \n",
      "0  \t10    \t0.975849\t0.933779\t1  \t0.0230376\n",
      "1  \t6     \t0.993656\t0.967724\t1  \t0.00955532\n",
      "2  \t7     \t0.999388\t0.997774\t1  \t0.000946021\n",
      "3  \t4     \t1       \t1       \t1  \t0          \n",
      "4  \t6     \t1       \t1       \t1  \t0          \n",
      "5  \t7     \t1       \t1       \t1  \t0          \n",
      "Best individual is: {'optimizer': 'adam', 'activation': 'relu', 'batch_size': 32, 'neurons': 82, 'epochs': 50, 'patience': 7}\n",
      "with fitness: 1.0\n",
      "{'optimizer': 'adam', 'activation': 'relu', 'batch_size': 32, 'neurons': 82, 'epochs': 50, 'patience': 7}\n",
      "Accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "def ANN(optimizer = 'sgd',neurons=32,batch_size=32,epochs=20,activation='relu',patience=3,loss='categorical_crossentropy'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_shape=(X.shape[1],), activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(10,activation='softmax'))  # 10 is the number of classes in the dataset, you can change it based on your dataset\n",
    "    model.compile(optimizer = optimizer, loss=loss)\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", patience = patience)# early stop patience\n",
    "    history = model.fit(X, pd.get_dummies(y).values,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              callbacks = [early_stopping],\n",
    "              verbose=0) #verbose set to 1 will show the training process\n",
    "    return model\n",
    "\n",
    "\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'optimizer': ['adam','rmsprop','sgd'],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'batch_size': [16,32,64],\n",
    "    'neurons':range(10,100),\n",
    "    'epochs':[20,50],\n",
    "    #'epochs':[20,50,100,200],\n",
    "    'patience':range(3,20)\n",
    "}\n",
    "clf = KerasClassifier(build_fn=ANN, verbose=0)\n",
    "# Set the hyperparameters of GA    \n",
    "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
    "                                   params=rf_params,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   cv=3,\n",
    "                                   verbose=1,\n",
    "                                   population_size=10,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=1)\n",
    "ga1.fit(X, y)\n",
    "print(ga1.best_params_)\n",
    "print(\"Accuracy:\"+ str(ga1.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using TPOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=25, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9454646633277685\tRandomForestClassifier(CombineDFs(input_matrix, input_matrix), RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=97, RandomForestClassifier__max_features=5, RandomForestClassifier__min_samples_leaf=1, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=179)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9454646633277685\tRandomForestClassifier(CombineDFs(input_matrix, input_matrix), RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=97, RandomForestClassifier__max_features=5, RandomForestClassifier__min_samples_leaf=1, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=179)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9454646633277685\tRandomForestClassifier(CombineDFs(input_matrix, input_matrix), RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=97, RandomForestClassifier__max_features=5, RandomForestClassifier__min_samples_leaf=1, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=179)\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.ensemble.RandomForestClassifier': {'criterion': ['gini',\n",
       "                                                                                      'entropy'],\n",
       "                                                                        'max_depth': range(10, 100),\n",
       "                                                                        'max_features': range(1, 64),\n",
       "                                                                        'min_samples_leaf': range(1, 11),\n",
       "                                                                        'min_samples_split': range(2, 11),\n",
       "                                                                        'n_estimators': range(20, 200)}},\n",
       "               cv=3, early_stop=5, generations=3, offspring_size=5,\n",
       "               population_size=10, scoring='accuracy', verbosity=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "from tpot import TPOTClassifier\n",
    "# Define the hyperparameter configuration space\n",
    "parameters = {\n",
    "        'n_estimators': range(20,200),\n",
    "    \"max_features\":range(1,64),\n",
    "    'max_depth': range(10,100),\n",
    "    \"min_samples_split\":range(2,11),\n",
    "    \"min_samples_leaf\":range(1,11),\n",
    "    \"criterion\":['gini','entropy']\n",
    "             }\n",
    "# Set the hyperparameters of GA                 \n",
    "ga2 = TPOTClassifier(generations= 3, population_size= 10, offspring_size= 5,\n",
    "                                 verbosity= 3, early_stop= 5,\n",
    "                                 config_dict=\n",
    "                                 {'sklearn.ensemble.RandomForestClassifier': parameters}, \n",
    "                                 cv = 3, scoring = 'accuracy')\n",
    "ga2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=25, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9738452977184195\tSVC(CombineDFs(input_matrix, input_matrix), SVC__C=49.8486617673746, SVC__kernel=rbf)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9738452977184195\tSVC(CombineDFs(input_matrix, input_matrix), SVC__C=49.8486617673746, SVC__kernel=rbf)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9738452977184195\tSVC(CombineDFs(input_matrix, input_matrix), SVC__C=49.8486617673746, SVC__kernel=rbf)\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.svm.SVC': {'C': array([5.10688833e+00, 4.99068702e+01, 3.42268065e+01, 2.93952246e+00,\n",
       "       4.27541697e-01, 4.81218196e+01, 1.66148413e+01, 3.00756992e-01,\n",
       "       4.94774433e+01, 3.87947769e+01, 3.09684589e+00, 1.54952320e+01,\n",
       "       2.07866181e+01, 1.28038842e+01, 1.92360590e+01, 4.92571547e+01,\n",
       "       2.80974955e+01, 1.64139467e+00, 3.29079470e+01, 6.46908...\n",
       "       2.98006653e+01, 2.03259444e+01, 1.61195448e+01, 5.75471731e+00,\n",
       "       1.96097420e+01, 1.15769103e+01, 3.38836913e+01, 3.31056785e+01,\n",
       "       5.76068848e+00, 1.99586594e+01, 3.42079696e+01, 3.83804909e+01,\n",
       "       2.77333514e+01, 1.72032263e+01, 4.60346408e+01, 4.02337723e+01]),\n",
       "                                                'kernel': ['linear', 'poly',\n",
       "                                                           'rbf', 'sigmoid']}},\n",
       "               cv=3, early_stop=5, generations=3, offspring_size=5,\n",
       "               population_size=10, scoring='accuracy', verbosity=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "parameters = {\n",
    "    'C': np.random.uniform(0,50,1000),\n",
    "    \"kernel\":['linear','poly','rbf','sigmoid']\n",
    "             }\n",
    "               \n",
    "ga2 = TPOTClassifier(generations= 3, population_size= 10, offspring_size= 5,\n",
    "                                 verbosity= 3, early_stop= 5,\n",
    "                                 config_dict=\n",
    "                                 {'sklearn.svm.SVC': parameters}, \n",
    "                                 cv = 3, scoring = 'accuracy')\n",
    "ga2.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=25, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9638286032276016\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=1)\n",
      "\n",
      "-2\t0.9654980523094046\tKNeighborsClassifier(KNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=17), KNeighborsClassifier__n_neighbors=4)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9682804674457429\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=3)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9682804674457429\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=3)\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.neighbors.KNeighborsClassifier': {'n_neighbors': range(1, 20)}},\n",
       "               cv=3, early_stop=5, generations=3, offspring_size=5,\n",
       "               population_size=10, scoring='accuracy', verbosity=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "parameters = {\n",
    "    'n_neighbors': range(1,20),\n",
    "             }\n",
    "               \n",
    "ga2 = TPOTClassifier(generations= 3, population_size= 10, offspring_size= 5,\n",
    "                                 verbosity= 3, early_stop= 5,\n",
    "                                 config_dict=\n",
    "                                 {'sklearn.neighbors.KNeighborsClassifier': parameters}, \n",
    "                                 cv = 3, scoring = 'accuracy')\n",
    "ga2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
