{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': '/home/test/anaconda3/envs/astrophysics123/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline Machine Learning models: Regressors with Default Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:30.461252451394756\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "clf = RandomForestRegressor()\n",
    "scores = cross_val_score(clf, X, y, cv=3,scoring='neg_mean_squared_error') # 3-fold cross-validation\n",
    "print(\"MSE:\"+ str(-scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:77.42951812579332\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "clf = SVR(gamma='scale')\n",
    "scores = cross_val_score(clf, X, y, cv=3,scoring='neg_mean_squared_error')\n",
    "print(\"MSE:\"+ str(-scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:81.48773186343571\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "clf = KNeighborsRegressor()\n",
    "scores = cross_val_score(clf, X, y, cv=3,scoring='neg_mean_squared_error')\n",
    "print(\"MSE:\"+ str(-scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "def ANN(optimizer = 'adam',neurons=32,batch_size=32,epochs=50,activation='relu',patience=5,loss='mse'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_shape=(X.shape[1],), activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = optimizer, loss=loss)\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", patience = patience)# early stop patience\n",
    "    history = model.fit(X, y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              callbacks = [early_stopping],\n",
    "              verbose=0) #verbose set to 1 will show the training process\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:43.86915343191351\n"
     ]
    }
   ],
   "source": [
    "clf = KerasRegressor(build_fn=ANN, verbose=0)\n",
    "scores = cross_val_score(clf, X, y, cv=3,scoring='neg_mean_squared_error')\n",
    "print(\"MSE:\"+ str(-scores.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HPO Algorithm 1: Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'n_estimators': 20}\n",
      "MSE:29.02394449507633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    #'max_features': ['sqrt',0.5],\n",
    "    'max_depth': [15,20,30,50],\n",
    "    #'min_samples_leaf': [1,2,4,8],\n",
    "    #\"bootstrap\":[True,False],\n",
    "    #\"criterion\":['mse','mae']\n",
    "}\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "grid = GridSearchCV(clf, rf_params, cv=3, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(\"MSE:\"+ str(-grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'epsilon': 0.01, 'kernel': 'poly'}\n",
      "MSE:67.07483887754718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_params = {\n",
    "    'C': [1,10, 100],\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    \"epsilon\":[0.01,0.1,1]\n",
    "}\n",
    "clf = SVR(gamma='scale')\n",
    "grid = GridSearchCV(clf, rf_params, cv=3, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(\"MSE:\"+ str(-grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5}\n",
      "MSE:81.52933517786562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_params = {\n",
    "    'n_neighbors': [2, 3, 5,7,10]\n",
    "}\n",
    "clf = KNeighborsRegressor()\n",
    "grid = GridSearchCV(clf, rf_params, cv=3, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(\"MSE:\"+ str(-grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 32, 'epochs': 50, 'loss': 'mse', 'neurons': 32, 'optimizer': 'adam', 'patience': 2}\n",
      "MSE:52.46714581852489\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_params = {\n",
    "    'optimizer': ['adam','rmsprop'],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'loss': ['mse','mae'],\n",
    "    'batch_size': [16,32],\n",
    "    'neurons':[16,32],\n",
    "    'epochs':[20,50],\n",
    "    'patience':[2,5]\n",
    "}\n",
    "clf = KerasRegressor(build_fn=ANN, verbose=0)\n",
    "grid = GridSearchCV(clf, rf_params, cv=3,scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(\"MSE:\"+ str(-grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HPO Algorithm 2: Random Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_depth': 47, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 59}\n",
      "MSE:27.396446279090135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': sp_randint(10,100),\n",
    "    \"max_features\":sp_randint(1,13),\n",
    "    'max_depth': sp_randint(5,50),\n",
    "    \"min_samples_split\":sp_randint(2,11),\n",
    "    \"min_samples_leaf\":sp_randint(1,11),\n",
    "    \"criterion\":['mse','mae']\n",
    "}\n",
    "n_iter_search=20 #number of iterations is set to 20, you can increase this number if time permits\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='neg_mean_squared_error')\n",
    "Random.fit(X, y)\n",
    "print(Random.best_params_)\n",
    "print(\"MSE:\"+ str(-Random.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 31.747323273178772, 'epsilon': 0.9051832494763797, 'kernel': 'poly'}\n",
      "MSE:60.22903886978192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_params = {\n",
    "    'C': stats.uniform(0,50),\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    \"epsilon\":stats.uniform(0,1)\n",
    "}\n",
    "n_iter_search=20\n",
    "clf = SVR(gamma='scale')\n",
    "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='neg_mean_squared_error')\n",
    "Random.fit(X, y)\n",
    "print(Random.best_params_)\n",
    "print(\"MSE:\"+ str(-Random.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 13}\n",
      "MSE:80.7723025469514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_params = {\n",
    "    'n_neighbors': sp_randint(1,20),\n",
    "}\n",
    "n_iter_search=10\n",
    "clf = KNeighborsRegressor()\n",
    "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='neg_mean_squared_error')\n",
    "Random.fit(X, y)\n",
    "print(Random.best_params_)\n",
    "print(\"MSE:\"+ str(-Random.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 16, 'epochs': 20, 'loss': 'mse', 'neurons': 70, 'optimizer': 'adam', 'patience': 4}\n",
      "MSE:38.45416595298494\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_params = {\n",
    "    'optimizer': ['adam','rmsprop'],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'loss': ['mse','mae'],\n",
    "    'batch_size': [16,32,64],\n",
    "    'neurons':sp_randint(10,100),\n",
    "    'epochs':[20,50],\n",
    "    #'epochs':[20,50,100,200],\n",
    "    'patience':sp_randint(3,20)\n",
    "}\n",
    "n_iter_search=10\n",
    "clf = KerasRegressor(build_fn=ANN, verbose=0)\n",
    "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='neg_mean_squared_error')\n",
    "Random.fit(X, y)\n",
    "print(Random.best_params_)\n",
    "print(\"MSE:\"+ str(-Random.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HPO Algorithm 3: Hyperband\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_depth': 11, 'max_features': 10, 'min_samples_leaf': 6, 'min_samples_split': 5, 'n_estimators': 11}\n",
      "MSE:27.82872118482073\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from hyperband import HyperbandSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': sp_randint(10,100),\n",
    "    \"max_features\":sp_randint(1,13),\n",
    "    'max_depth': sp_randint(5,50),\n",
    "    \"min_samples_split\":sp_randint(2,11),\n",
    "    \"min_samples_leaf\":sp_randint(1,11),\n",
    "    \"criterion\":['mse','mae']\n",
    "}\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=10,max_iter=100,scoring='neg_mean_squared_error')\n",
    "hyper.fit(X, y)\n",
    "print(hyper.best_params_)\n",
    "print(\"MSE:\"+ str(-hyper.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'epsilon': 0.029177342506488846, 'kernel': 'rbf'}\n",
      "MSE:72.83527663803682\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from hyperband import HyperbandSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "rf_params = {\n",
    "    'C': stats.uniform(0,50),\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    \"epsilon\":stats.uniform(0,1)\n",
    "}\n",
    "clf = SVR(gamma='scale')\n",
    "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=1,max_iter=10,scoring='neg_mean_squared_error',resource_param='C')\n",
    "hyper.fit(X, y)\n",
    "print(hyper.best_params_)\n",
    "print(\"MSE:\"+ str(-hyper.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 6}\n",
      "MSE:80.87024044795783\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from hyperband import HyperbandSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "rf_params = {\n",
    "    'n_neighbors': range(1,20),\n",
    "}\n",
    "clf = KNeighborsRegressor()\n",
    "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=1,max_iter=20,scoring='neg_mean_squared_error',resource_param='n_neighbors')\n",
    "hyper.fit(X, y)\n",
    "print(hyper.best_params_)\n",
    "print(\"MSE:\"+ str(-hyper.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'epochs': 10, 'loss': 'mse', 'neurons': 84, 'optimizer': 'adam', 'patience': 16}\n",
      "MSE:83.31618953604321\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "from hyperband import HyperbandSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "rf_params = {\n",
    "    'optimizer': ['adam','rmsprop'],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'loss': ['mse','mae'],\n",
    "    'batch_size': [16,32,64],\n",
    "    'neurons':sp_randint(10,100),\n",
    "    'epochs':[20,50],\n",
    "    #'epochs':[20,50,100,200],\n",
    "    'patience':sp_randint(3,20)\n",
    "}\n",
    "clf = KerasRegressor(build_fn=ANN, epochs=20, verbose=0)\n",
    "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=1,max_iter=10,scoring='neg_mean_squared_error',resource_param='epochs')\n",
    "hyper.fit(X, y)\n",
    "print(hyper.best_params_)\n",
    "print(\"MSE:\"+ str(-hyper.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HPO Algorithm 4: BO-GP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Using skopt.BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('criterion', 'mae'), ('max_depth', 36), ('max_features', 7), ('min_samples_leaf', 1), ('min_samples_split', 11), ('n_estimators', 45)])\n",
      "MSE:27.200855650493327\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': Integer(10,100),\n",
    "    \"max_features\":Integer(1,13),\n",
    "    'max_depth': Integer(5,50),\n",
    "    \"min_samples_split\":Integer(2,11),\n",
    "    \"min_samples_leaf\":Integer(1,11),\n",
    "    \"criterion\":['mse','mae']\n",
    "}\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, scoring='neg_mean_squared_error') \n",
    "#number of iterations is set to 20, you can increase this number if time permits\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "bclf = Bayes.best_estimator_\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('C', 49.683018375532924), ('epsilon', 0.013241640863736363), ('kernel', 'poly')])\n",
      "MSE:59.267259166172174\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "rf_params = {\n",
    "    'C': Real(0,50),\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    'epsilon': Real(0,1)\n",
    "}\n",
    "clf = SVR(gamma='scale')\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, scoring='neg_mean_squared_error')\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('n_neighbors', 13)])\n",
      "MSE:80.74121499347262\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "rf_params = {\n",
    "    'n_neighbors': Integer(1,20),\n",
    "}\n",
    "clf = KNeighborsRegressor()\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=10, scoring='neg_mean_squared_error')\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('activation', 'relu'), ('batch_size', 32), ('epochs', 24), ('loss', 'mae'), ('neurons', 47), ('optimizer', 'adam'), ('patience', 14)])\n",
      "MSE:44.03458020922383\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "rf_params = {\n",
    "    'optimizer': ['adam','rmsprop'],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'loss': ['mse','mae'],\n",
    "    'batch_size': [16,32,64],\n",
    "    'neurons':Integer(10,100),\n",
    "    'epochs':[20,50],\n",
    "    #'epochs':[20,50,100,200],\n",
    "    'patience':Integer(3,20)\n",
    "}\n",
    "clf = KerasRegressor(build_fn=ANN, verbose=0)\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=10, scoring='neg_mean_squared_error')\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Using skopt.gp_minimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('criterion', 'mse'), ('max_depth', 22), ('max_features', 7), ('min_samples_leaf', 1), ('min_samples_split', 6), ('n_estimators', 57)])\n",
      "MSE:25.46298194972694\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': Integer(10,100),\n",
    "    \"max_features\":Integer(1,13),\n",
    "    'max_depth': Integer(5,50),\n",
    "    \"min_samples_split\":Integer(2,11),\n",
    "    \"min_samples_leaf\":Integer(1,11),\n",
    "    \"criterion\":['mse','mae']\n",
    "}\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, scoring='neg_mean_squared_error') \n",
    "#number of iterations is set to 20, you can increase this number if time permits\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "bclf = Bayes.best_estimator_\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('C', 37.8104361880082), ('epsilon', 0.6904621349570833), ('kernel', 'poly')])\n",
      "MSE:60.64876628704073\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "rf_params = {\n",
    "    'C': Real(0,50),\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    'epsilon': Real(0,1)\n",
    "}\n",
    "clf = SVR(gamma='scale')\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, scoring='neg_mean_squared_error')\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('n_neighbors', 12)])\n",
      "MSE:81.34909773097274\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "rf_params = {\n",
    "    'n_neighbors': Integer(1,20),\n",
    "}\n",
    "clf = KNeighborsRegressor()\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=10, scoring='neg_mean_squared_error')\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('activation', 'relu'), ('batch_size', 32), ('epochs', 43), ('loss', 'mse'), ('neurons', 99), ('optimizer', 'adam'), ('patience', 16)])\n",
      "MSE:41.933040247226636\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "rf_params = {\n",
    "    'optimizer': ['adam','rmsprop'],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'loss': ['mse','mae'],\n",
    "    'batch_size': [16,32,64],\n",
    "    'neurons':Integer(10,100),\n",
    "    'epochs':[20,50],\n",
    "    #'epochs':[20,50,100,200],\n",
    "    'patience':Integer(3,20)\n",
    "}\n",
    "clf = KerasRegressor(build_fn=ANN, verbose=0)\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=10, scoring='neg_mean_squared_error')\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:25.8747\n",
      "[45, 43, 5, 8, 5, 'mse']\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "reg = RandomForestRegressor()\n",
    "# Define the hyperparameter configuration space\n",
    "space  = [Integer(10, 100, name='n_estimators'),\n",
    "            Integer(5, 50, name='max_depth'),\n",
    "          Integer(1, 13, name='max_features'),\n",
    "          Integer(2, 11, name='min_samples_split'),\n",
    "          Integer(1, 11, name='min_samples_leaf'),\n",
    "         Categorical(['mse', 'mae'], name='criterion')\n",
    "         ]\n",
    "# Define the objective function\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "#number of iterations is set to 20, you can increase this number if time permits\n",
    "print(\"MSE:%.4f\" % res_gp.fun)\n",
    "print(res_gp.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:61.2510\n",
      "[37.93078121611787, 'poly', 0.47360041934665753]\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "reg = SVR(gamma='scale')\n",
    "space  = [Real(0, 50, name='C'),\n",
    "          Categorical(['poly','rbf','sigmoid'], name='kernel'),\n",
    "          Real(0, 1, name='epsilon'),\n",
    "         ]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "print(\"MSE:%.4f\" % res_gp.fun)\n",
    "print(res_gp.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:80.7412\n",
      "[13]\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "reg = KNeighborsRegressor()\n",
    "space  = [Integer(1, 20, name='n_neighbors')]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=10, random_state=0)\n",
    "print(\"MSE:%.4f\" % res_gp.fun)\n",
    "print(res_gp.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### HPO Algorithm 5: BO-TPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.35trial/s, best loss: 26.97630991791949]\n",
      "Random Forest: Hyperopt estimated optimum {'criterion': 0, 'max_depth': 42.0, 'max_features': 8.0, 'min_samples_leaf': 8.0, 'min_samples_split': 3.0, 'n_estimators': 75.0}\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']), \n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'max_features': int(params['max_features']),\n",
    "        \"min_samples_split\":int(params['min_samples_split']),\n",
    "        \"min_samples_leaf\":int(params['min_samples_leaf']),\n",
    "        \"criterion\":str(params['criterion'])\n",
    "    }\n",
    "    clf = RandomForestRegressor( **params)\n",
    "    score = -np.mean(cross_val_score(clf, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "    return {'loss':score, 'status': STATUS_OK }\n",
    "# Define the hyperparameter configuration space\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 100, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 50, 1),\n",
    "    \"max_features\":hp.quniform('max_features', 1, 13, 1),\n",
    "    \"min_samples_split\":hp.quniform('min_samples_split',2,11,1),\n",
    "    \"min_samples_leaf\":hp.quniform('min_samples_leaf',1,11,1),\n",
    "    \"criterion\":hp.choice('criterion',['mse','mae'])\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 52.81trial/s, best loss: 60.31133170451198]\n",
      "SVM: Hyperopt estimated optimum {'C': 30.45675844585344, 'epsilon': 0.4757626860624949, 'kernel': 0}\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'C': abs(float(params['C'])), \n",
    "        \"kernel\":str(params['kernel']),\n",
    "        'epsilon': abs(float(params['epsilon'])),\n",
    "    }\n",
    "    clf = SVR(gamma='scale', **params)\n",
    "    score = -np.mean(cross_val_score(clf, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "    \n",
    "    return {'loss':score, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'C': hp.normal('C', 0, 50),\n",
    "    \"kernel\":hp.choice('kernel',['poly','rbf','sigmoid']),\n",
    "    'epsilon': hp.normal('epsilon', 0, 1),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"SVM: Hyperopt estimated optimum {}\".format(best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 97.74trial/s, best loss: 80.83005201647829]\n",
      "KNN: Hyperopt estimated optimum {'n_neighbors': 6.0}\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_neighbors': abs(int(params['n_neighbors']))\n",
    "    }\n",
    "    clf = KNeighborsRegressor( **params)\n",
    "    score = -np.mean(cross_val_score(clf, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "    return {'loss':score, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'n_neighbors': hp.quniform('n_neighbors', 1, 20, 1),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"KNN: Hyperopt estimated optimum {}\".format(best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:14<00:00,  7.42s/trial, best loss: 50.18424888351995]\n",
      "ANN: Hyperopt estimated optimum {'activation': 0, 'batch_size': 32.0, 'epochs': 40.0, 'loss': 1, 'neurons': 30.0, 'optimizer': 0, 'patience': 18.0}\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def objective(params):\n",
    "    params = {\n",
    "        \"optimizer\":str(params['optimizer']),\n",
    "        \"activation\":str(params['activation']),\n",
    "        \"loss\":str(params['loss']),\n",
    "        'batch_size': abs(int(params['batch_size'])),\n",
    "        'neurons': abs(int(params['neurons'])),\n",
    "        'epochs': abs(int(params['epochs'])),\n",
    "        'patience': abs(int(params['patience']))\n",
    "    }\n",
    "    clf = KerasRegressor(build_fn=ANN,**params, verbose=0)\n",
    "    score = -np.mean(cross_val_score(clf, X, y, cv=3, \n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "    return {'loss':score, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    \"optimizer\":hp.choice('optimizer',['adam','rmsprop']),\n",
    "    \"activation\":hp.choice('activation',['relu','tanh']),\n",
    "    \"loss\":hp.choice('loss',['mse','mae']),\n",
    "    'batch_size': hp.quniform('batch_size', 16, 64, 16),\n",
    "    'neurons': hp.quniform('neurons', 10, 100, 10),\n",
    "    'epochs': hp.quniform('epochs', 20, 50, 10),\n",
    "    'patience': hp.quniform('patience', 3, 20, 3),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"ANN: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HPO Algorithm 6: PSO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 51.8798828125, 'max_features': 8.951171875, 'max_depth': 18.33740234375, 'min_samples_split': 6.21435546875, 'min_samples_leaf': 3.9052734375}\n",
      "MSE:27.259215080169678\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "# Define the hyperparameter configuration space\n",
    "search = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'max_features': [1, 13],\n",
    "    'max_depth': [5,50],\n",
    "    \"min_samples_split\":[2,11],\n",
    "    \"min_samples_leaf\":[1,11],\n",
    "         }\n",
    "# Define the objective function\n",
    "@optunity.cross_validated(x=X, y=y, num_folds=3)\n",
    "def performance(x_train, y_train, x_test, y_test,n_estimators=None, max_features=None,max_depth=None,min_samples_split=None,min_samples_leaf=None):\n",
    "    # fit the model\n",
    "    model = RandomForestRegressor(n_estimators=int(n_estimators),\n",
    "                                   max_features=int(max_features),\n",
    "                                   max_depth=int(max_depth),\n",
    "                                   min_samples_split=int(min_samples_split),\n",
    "                                   min_samples_leaf=int(min_samples_leaf),\n",
    "                                  )\n",
    "    scores=-np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "    return scores\n",
    "\n",
    "optimal_configuration, info, _ = optunity.minimize(performance,\n",
    "                                                  solver_name='particle swarm',\n",
    "                                                  num_evals=20,\n",
    "                                                   **search\n",
    "                                                  )\n",
    "print(optimal_configuration)\n",
    "print(\"MSE:\"+ str(info.optimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 32.7099609375, 'kernel': 0.7766601562500002, 'epsilon': 0.31064453125}\n",
      "MSE:59.758334163239816\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "search = {\n",
    "    'C': (0,50),\n",
    "    'kernel':[0,3],\n",
    "    'epsilon': (0, 1)\n",
    "         }\n",
    "@optunity.cross_validated(x=X, y=y, num_folds=3)\n",
    "def performance(x_train, y_train, x_test, y_test,C=None,kernel=None,epsilon=None):\n",
    "    # fit the model\n",
    "    if kernel<1:\n",
    "        ke='poly'\n",
    "    elif kernel<2:\n",
    "        ke='rbf'\n",
    "    else:\n",
    "        ke='sigmoid'\n",
    "    model = SVR(C=float(C),\n",
    "                kernel=ke,\n",
    "                gamma='scale',\n",
    "                epsilon=float(epsilon)\n",
    "                                  )\n",
    "\n",
    "    scores=-np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "    return scores\n",
    "\n",
    "optimal_configuration, info, _ = optunity.minimize(performance,\n",
    "                                                  solver_name='particle swarm',\n",
    "                                                  num_evals=20,\n",
    "                                                   **search\n",
    "                                                  )\n",
    "print(optimal_configuration)\n",
    "print(\"MSE:\"+ str(info.optimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 14.0439453125}\n",
      "MSE:81.26511555604914\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "search = {\n",
    "    'n_neighbors': [1, 20],\n",
    "         }\n",
    "@optunity.cross_validated(x=X, y=y, num_folds=3)\n",
    "def performance(x_train, y_train, x_test, y_test,n_neighbors=None):\n",
    "    # fit the model\n",
    "    model = KNeighborsRegressor(n_neighbors=int(n_neighbors),\n",
    "                                  )\n",
    "\n",
    "    scores=-np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "    return scores\n",
    "\n",
    "optimal_configuration, info, _ = optunity.minimize(performance,\n",
    "                                                  solver_name='particle swarm',\n",
    "                                                  num_evals=10,\n",
    "                                                   **search\n",
    "                                                  )\n",
    "print(optimal_configuration)\n",
    "print(\"MSE:\"+ str(info.optimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 0.7873046875, 'activation': 1.4373046875, 'loss': 0.8923828125, 'batch_size': 0.7119605382156127, 'neurons': 46.9228515625, 'epochs': 49.1181640625, 'patience': 11.50166015625}\n",
      "MSE:36.97802766465484\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "search = {\n",
    "    'optimizer':[0,2],\n",
    "    'activation':[0,2],\n",
    "    'loss':[0,2],\n",
    "    'batch_size': [0, 2],\n",
    "    'neurons': [10, 100],\n",
    "    'epochs': [20, 50],\n",
    "    'patience': [3, 20],\n",
    "         }\n",
    "@optunity.cross_validated(x=X, y=y, num_folds=3)\n",
    "def performance(x_train, y_train, x_test, y_test,optimizer=None,activation=None,loss=None,batch_size=None,neurons=None,epochs=None,patience=None):\n",
    "    # fit the model\n",
    "    if optimizer<1:\n",
    "        op='adam'\n",
    "    else:\n",
    "        op='rmsprop'\n",
    "    if activation<1:\n",
    "        ac='relu'\n",
    "    else:\n",
    "        ac='tanh'\n",
    "    if loss<1:\n",
    "        lo='mse'\n",
    "    else:\n",
    "        lo='mae'\n",
    "    if batch_size<1:\n",
    "        ba=16\n",
    "    else:\n",
    "        ba=32\n",
    "    model = ANN(optimizer=op,\n",
    "                activation=ac,\n",
    "                loss=lo,\n",
    "                batch_size=ba,\n",
    "                neurons=int(neurons),\n",
    "                epochs=int(epochs),\n",
    "                patience=int(patience)\n",
    "                                  )\n",
    "    clf = KerasRegressor(build_fn=ANN, verbose=0)\n",
    "    scores=-np.mean(cross_val_score(clf, X, y, cv=3, \n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "    return scores\n",
    "\n",
    "optimal_configuration, info, _ = optunity.minimize(performance,\n",
    "                                                  solver_name='particle swarm',\n",
    "                                                  num_evals=20,\n",
    "                                                   **search\n",
    "                                                  )\n",
    "print(optimal_configuration)\n",
    "print(\"MSE:\"+ str(info.optimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
